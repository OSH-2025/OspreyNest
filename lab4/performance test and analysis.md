### 一 LLM 部署性能指标列表
在 LLM（大语言模型 ）部署场景中，为全面评估模型在实际应用里的表现，从**效率、资源、体验、质量**等维度，选取以下性能指标：

#### 1. 输出速度（Tokens per Second, TPS）
- **定义**：模型每秒能生成的 Token 数量，反映文本生成的效率。  
- **合理性**：直接决定用户交互的等待时长。在对话场景中，输出速度快可让用户快速获得回复；长文本生成任务里，高 TPS 能大幅缩短整体耗时，提升使用体验与工作效率。

#### 2. 首 Token 延迟（First Token Latency）
- **定义**：从输入请求发起到模型输出第一个 Token 的时间间隔。  
- **合理性**：决定用户对“响应及时性”的感知。在实时对话中，首 Token 延迟低，能让用户感觉交互流畅、无卡顿，是影响体验的关键指标。

#### 3. 内存占用峰值（Peak Memory Usage）
- **定义**：模型推理过程中，内存消耗的最大值。  
- **合理性**：决定部署的硬件适配性。普通单机（如个人电脑、边缘设备 ）内存资源有限，若峰值过高，会导致内存溢出、程序崩溃，或与其他进程抢占资源引发系统卡顿，需通过该指标平衡模型能力与硬件成本。

#### 4. CPU 利用率（CPU Utilization）
- **定义**：推理时 CPU 核心的平均占用比例（多核心场景下可细分单核/多核利用率 ）。  
- **合理性**：反映 CPU 资源的消耗程度。过高的利用率会导致系统响应变慢（如其他程序无法正常运行 ），过低则说明硬件算力未充分利用。需通过该指标优化参数，让模型推理与系统稳定性协同。

#### 5. 多轮对话上下文保持率（Multi - turn Context Retention Rate）
- **定义**：长对话场景中，模型生成内容与历史上下文的关联度（可通过人工评估、语义相似度算法等量化 ，如 1 - 5 分制 ）。  
- **合理性**：衡量模型复杂交互能力。实际应用（如多轮问答、持续对话 ）中，若上下文断裂，会严重影响体验与功能可用性，该指标能评估模型在真实业务流程里的表现。


#### 6. 批处理吞吐量（Batch Throughput）
- **定义**：单位时间内，模型能处理的批请求数量（适合批量推理场景，如文本批量生成、智能文档处理 ）。  
- **合理性**：体现模型在高并发、批量任务中的效率，对企业级批量处理业务（如内容生成平台 ）至关重要。
