# lab4实验说明
我们选择的是llama.cpp（LLM 部署、推理相关）
### 完成实验要求（llama.cpp）：
拟定一份 LLM 部署相关的性能指标列表（不少于 5 个指标，如输出速度、首 Token 返回延迟 等），并说明所选指标的合理性。（1 分）
设计测试任务（可以直接使用llama.cpp 自带的测试工具等），并根据测试任务，从指标列表中选择至少两个指标进行后续测试。（1 分）
选取一款合适的 LLM，完成单机版部署并进行性能测试。（5 分）
基于已有部署参数进行分析、测试和优化。优化以 llama.cpp 的配置参数修改为主，不必修改底层系统环境，但需给出相应分析。（2 分）
选取对于所选性能指标以及 LLM 输出质量影响最大的优化操作，分析并说明原因。完成2项优化。（1 项优化 / 1 分，最高 3 分）
将撰写的相关报告发布到公开媒体，如 CSDN、知乎或是自己的博客、channel，并在报告中提供链接。（1 分）
